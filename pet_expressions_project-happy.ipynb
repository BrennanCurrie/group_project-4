{"cells":[{"cell_type":"code","execution_count":12,"id":"e508faf6","metadata":{"id":"e508faf6","executionInfo":{"status":"ok","timestamp":1690859726910,"user_tz":360,"elapsed":205,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}}},"outputs":[],"source":["# Import Dependencies\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"]},{"cell_type":"code","source":["# Set up Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TPEdqWkAlKQ","executionInfo":{"status":"ok","timestamp":1690859728597,"user_tz":360,"elapsed":710,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}},"outputId":"c94e515c-a259-44b5-f096-ab28b4f15eb7"},"id":"_TPEdqWkAlKQ","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Change Directory\n","%cd /content/drive/MyDrive/pet_expressions_data/happy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMkxM8-gBy8U","executionInfo":{"status":"ok","timestamp":1690859729469,"user_tz":360,"elapsed":4,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}},"outputId":"2840ed9a-7f47-48ad-e511-04a6a411b0cc"},"id":"yMkxM8-gBy8U","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/pet_expressions_data/happy\n"]}]},{"cell_type":"code","source":["# Define the path to the dataset folders\n","happy_folder = \"/content/drive/MyDrive/pet_expressions_data/happy\"\n","sad_folder = \"/content/drive/MyDrive/pet_expressions_data/sad\"\n","angry_folder = \"/content/drive/MyDrive/pet_expressions_data/angry\"\n","other_folder = \"/content/drive/MyDrive/pet_expressions_data/other\""],"metadata":{"id":"oHd6VWxVCdMn","executionInfo":{"status":"ok","timestamp":1690860635041,"user_tz":360,"elapsed":201,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}}},"id":"oHd6VWxVCdMn","execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Function to load and preprocess images\n","def load_images_from_folder(folder):\n","    images = []\n","    for folder in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n","            images.append(img)\n","    return images"],"metadata":{"id":"gHD-rY4OGUdC","executionInfo":{"status":"ok","timestamp":1690859991134,"user_tz":360,"elapsed":204,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}}},"id":"gHD-rY4OGUdC","execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":20,"id":"c76b61aa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"c76b61aa","executionInfo":{"status":"error","timestamp":1690860642254,"user_tz":360,"elapsed":199,"user":{"displayName":"Brennan Currie","userId":"11818399872199193995"}},"outputId":"646efa4e-7a11-41d6-aead-7b6349c9e7e9"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-43323662d954>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load images and labels for each emotion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhappy_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhappy_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msad_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msad_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mangry_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangry_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mother_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-79991a025cc8>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}],"source":["# Load images and labels for each emotion\n","happy_images = load_images_from_folder(happy_folder)\n","sad_images = load_images_from_folder(sad_folder)\n","angry_images = load_images_from_folder(angry_folder)\n","other_images = load_images_from_folder(other_folder)"]},{"cell_type":"code","source":["# Create labels for each emotion category\n","happy_labels = [0] * len(happy_images)\n","sad_labels = [1] * len(sad_images)\n","angry_labels = [2] * len(angry_images)"],"metadata":{"id":"7Y5JhOxVEjK5"},"id":"7Y5JhOxVEjK5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate images and labels\n","X = np.array(happy_images + sad_images + angry_images)\n","y = np.array(happy_labels + sad_labels + angry_labels)"],"metadata":{"id":"fE_-U9oSHLmz"},"id":"fE_-U9oSHLmz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize pixel values to range [0, 1]\n","X = X.astype('float32') / 255.0"],"metadata":{"id":"Bggs4WygHL4K"},"id":"Bggs4WygHL4K","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One-hot encode the labels\n","y = np_utils.to_categorical(y, 3)"],"metadata":{"id":"CF-FOR4KHSz1"},"id":"CF-FOR4KHSz1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"yDNk4ib-HT_T"},"id":"yDNk4ib-HT_T","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the CNN model\n","model = Sequential()\n","\n","model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3, activation='softmax'))\n"],"metadata":{"id":"KgUfjvf2HU8d"},"id":"KgUfjvf2HU8d","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.summary())\n"],"metadata":{"id":"OmWF4GxFHa43"},"id":"OmWF4GxFHa43","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model with class weights\n","model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])"],"metadata":{"id":"lvBqJ4mcHrUc"},"id":"lvBqJ4mcHrUc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate class weights\n","total_samples = len(y_train)\n","class_weights = {0: total_samples / np.sum(y_train[:, 0]),\n","                 1: total_samples / np.sum(y_train[:, 1]),\n","                 2: total_samples / np.sum(y_train[:, 2])}"],"metadata":{"id":"yMOh7_jfHbUD"},"id":"yMOh7_jfHbUD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model with class weights\n","history = model.fit(X_train.reshape(-1, 48, 48, 1), y_train, batch_size=32, epochs=100, validation_split=0.1, class_weight=class_weights,verbose=0)"],"metadata":{"id":"x7mOQuyZHbem"},"id":"x7mOQuyZHbem","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model on test data\n","loss, accuracy = model.evaluate(X_test.reshape(-1, 48, 48, 1), y_test)\n","losstr, accuracytr = model.evaluate(X_train.reshape(-1, 48, 48, 1), y_train)"],"metadata":{"id":"hRxtTSSLHbui"},"id":"hRxtTSSLHbui","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","model.save(\"facial_expression_model.h5\")"],"metadata":{"id":"7cVxMa7bH3he"},"id":"7cVxMa7bH3he","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Test accuracy: {accuracy*100:.2f}%\")\n","print(f\"Train accuracy: {accuracytr*100:.2f}%\")"],"metadata":{"id":"aXvewKI2H3tq"},"id":"aXvewKI2H3tq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##################################################################################"],"metadata":{"id":"J9TWPC47I8WW"},"id":"J9TWPC47I8WW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","# Load the saved model\n","loaded_model = load_model(\"facial_expression_model.h5\")"],"metadata":{"id":"OI2oPULfH34N"},"id":"OI2oPULfH34N","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to load and preprocess images\n","def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n","            images.append(img)\n","    return images"],"metadata":{"id":"vApWzW3iIBOL"},"id":"vApWzW3iIBOL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a custom test image\n","custom_test_image_path = \"/kaggle/input/pets-facial-expression-dataset/Angry/16924834.jpg\"\n","\n","custom_test_image = cv2.imread(custom_test_image_path)\n","custom_test_image = cv2.cvtColor(custom_test_image, cv2.COLOR_BGR2GRAY)\n","custom_test_image = cv2.resize(custom_test_image, (48, 48))\n","custom_test_image = custom_test_image.astype('float32') / 255.0"],"metadata":{"id":"G2hJ_t8uIBXv"},"id":"G2hJ_t8uIBXv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reshape the image to match the model input shape\n","custom_test_image = np.expand_dims(custom_test_image, axis=0)\n","custom_test_image = np.expand_dims(custom_test_image, axis=-1)"],"metadata":{"id":"zoagi0XAIBhH"},"id":"zoagi0XAIBhH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions on the custom test image\n","prediction = loaded_model.predict(custom_test_image)\n","prediction_prob = prediction[0]"],"metadata":{"id":"r39cICOXIBqP"},"id":"r39cICOXIBqP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_label = np.argmax(prediction[0])"],"metadata":{"id":"4QkEWBRMIBzy"},"id":"4QkEWBRMIBzy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Map the predicted label to emotion class\n","emotion_classes = {0: 'happy', 1: 'sad', 2: 'angry'}\n","predicted_emotion = emotion_classes[emotion_label]"],"metadata":{"id":"CiimcfpxH4CD"},"id":"CiimcfpxH4CD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the custom test image and its predicted label\n","print(f\"Predicted Emotion: {predicted_emotion}\")\n","print(f\"Confidence [happy, sad, angry]: {prediction_prob}\")"],"metadata":{"id":"MF1XmXXHImD9"},"id":"MF1XmXXHImD9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","#Display the custom test image using matplotlib\n","plt.imshow(custom_test_image[0, :, :, 0])\n","plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n","plt.axis('off')  # Hide axes\n","plt.show()"],"metadata":{"id":"25M2Dw8nImNk"},"id":"25M2Dw8nImNk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","# Display the original custom test image using PIL\n","img_pil = Image.open(custom_test_image_path)\n","plt.imshow(np.array(img_pil))\n","plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n","plt.axis('off')  # Hide axes\n","plt.show()"],"metadata":{"id":"VgZQk-xoImVE"},"id":"VgZQk-xoImVE","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CUAccvZBImcy"},"id":"CUAccvZBImcy","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fmsCn2X_Imkb"},"id":"fmsCn2X_Imkb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}